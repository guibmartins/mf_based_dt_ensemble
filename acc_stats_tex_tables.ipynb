{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "strategic-matthew",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import util as u\n",
    "\n",
    "# Statistical tests\n",
    "from scipy.stats import wilcoxon"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "listed-michael",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialization parameters\n",
    "k_factors = 2\n",
    "baseline = 'opf' # or knn\n",
    "datasets = ['Blood', 'Cancer', 'CMC', 'Digits', 'Iris']\n",
    "cols_acc = ['acc_baseline', 'acc_nmf', 'acc_pmf', 'acc_svd']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "rapid-thermal",
   "metadata": {},
   "outputs": [],
   "source": [
    "project_dir = '/'.join([os.getcwd(), 'out', 'KIS_21', f'k_{k_factors}'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "corporate-morrison",
   "metadata": {},
   "source": [
    "### Calculate statistics (wilcoxon signed-rank test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "stunning-firewall",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_acc_latex = pd.DataFrame(data=None, columns=cols_acc)\n",
    "\n",
    "for dataset in datasets:\n",
    "    \n",
    "    dataset = dataset.lower()\n",
    "    \n",
    "    l_stats = []\n",
    "    df_stats_sparse = pd.DataFrame()\n",
    "\n",
    "    # Get results for different levels of sparsity\n",
    "    for j in range(10, 80 + 10, 10):\n",
    "\n",
    "        sheet = f'S_{j:.1f}'\n",
    "        df_stats = pd.DataFrame()\n",
    "        i = 1\n",
    "\n",
    "        # Read NMF results\n",
    "        mf = 'nmf'\n",
    "        df_nmf = pd.DataFrame()\n",
    "        # Read all sheets from every experimental results xlsx file.\n",
    "        for entry in os.scandir('/'.join([project_dir, baseline, mf, dataset])):\n",
    "\n",
    "            if entry.path.endswith('.xlsx'):\n",
    "\n",
    "                df = pd.read_excel(entry.path, sheet_name=sheet, usecols='C, J')\n",
    "                df.columns = [f'acc_{mf}', f'time_{mf}']\n",
    "\n",
    "                # Calculate the results' mean for every sparsity level\n",
    "                df_nmf[str(i)] = df.mean(axis=0)\n",
    "                i += 1\n",
    "\n",
    "\n",
    "        # Read PMF results\n",
    "        i = 1\n",
    "        mf = 'pmf'\n",
    "        df_pmf = pd.DataFrame()\n",
    "        for entry in os.scandir('/'.join([project_dir, baseline, mf, dataset])):\n",
    "\n",
    "            if entry.path.endswith('.xlsx'):\n",
    "\n",
    "                df = pd.read_excel(entry.path, sheet_name=sheet, usecols='C, J')\n",
    "                df.columns = [f'acc_{mf}', f'time_{mf}']\n",
    "\n",
    "                # Calculate the average result for each level of sparsity\n",
    "                df_pmf[str(i)] = df.mean(axis=0)\n",
    "                i += 1\n",
    "\n",
    "\n",
    "        # Read SVD results\n",
    "        i = 1\n",
    "        mf = 'svd'\n",
    "        df_svd = pd.DataFrame()\n",
    "        for entry in os.scandir('/'.join([project_dir, baseline, mf, dataset])):\n",
    "\n",
    "            if entry.path.endswith('.xlsx'):\n",
    "\n",
    "                df = pd.read_excel(entry.path, sheet_name=sheet, usecols='B, C, G, J')\n",
    "                df.columns = [f'acc_baseline', f'acc_{mf}', f'time_baseline', f'time_{mf}']\n",
    "\n",
    "                # Calculate the average result for each level of sparsity\n",
    "                df_svd[str(i)] = df.mean(axis=0)\n",
    "                i += 1\n",
    "\n",
    "        # Concatenating MF dataframes\n",
    "        #df_res = pd.concat([df_nmf.T[['acc_baseline', 'time_baseline']], df_nmf.T[['acc_nmf', 'time_nmf']], df_pmf.T, df_svd.T], axis=1)\n",
    "        df_res = pd.concat([df_svd.T[['acc_baseline', 'time_baseline']], df_nmf.T, df_pmf.T, df_svd.T[['acc_svd', 'time_svd']]], axis=1)\n",
    "        \n",
    "        # Make a list of dataframes (each for a different sparsity level) \n",
    "        l_stats.append(df_res)\n",
    "\n",
    "    \n",
    "    # Select a baseline array at random\n",
    "    idx_baseline = np.random.randint(0, high=len(l_stats))\n",
    "#     aprint(f'Selected baseline array: {idx_baseline}')\n",
    "\n",
    "    for j in range(len(l_stats)):\n",
    "\n",
    "        # Read dataframe (__% of sparsity)\n",
    "        df = l_stats[j]\n",
    "\n",
    "        # Change baseline results to the ones selected randomly\n",
    "        df['acc_baseline'] = l_stats[idx_baseline]['acc_baseline']\n",
    "\n",
    "        # Calculate the average/standard deviation accuracy for each column\n",
    "        avg_acc, std_acc = df[cols_acc].mean(), df[cols_acc].std()\n",
    "\n",
    "        # Take the index of the best mean accuracy\n",
    "        idx_best = avg_acc.idxmax()\n",
    "\n",
    "        new_row = {idx_best: '\\\\bm{$' + str(avg_acc[idx_best].round(4)) + ' \\\\pm ' + str(std_acc[idx_best].round(4)) + '$}'}\n",
    "\n",
    "        # Make a list with the remaining results (except the best)\n",
    "        algs_acc = list(avg_acc.index.values)\n",
    "        algs_acc.remove(idx_best)\n",
    "\n",
    "        # Set the control group (G1)\n",
    "        g_crt = df[idx_best].values\n",
    "\n",
    "        # Statistical significance\n",
    "        alpha = 0.05\n",
    "\n",
    "        for idx_cmp in algs_acc:\n",
    "\n",
    "            # Set the algorithm (G2) to be compared against G1\n",
    "            g_cmp = df[idx_cmp].values\n",
    "            \n",
    "            # Perform the Wilcoxon signed-rank test\n",
    "            stat, p = wilcoxon(g_crt, g_cmp, zero_method='zsplit')\n",
    "\n",
    "            # Reject H0/ Accept H1 (Data come from distribution with different medians)\n",
    "            avg_std_tex = '$' + str(avg_acc[idx_cmp].round(4)) + ' \\\\pm ' + str(std_acc[idx_cmp].round(4)) + '$'\n",
    "\n",
    "            if p > alpha:\n",
    "                # Fail to reject H0 (i.e, accepts H0) \n",
    "                # (Distributions are similar based on their medians)\n",
    "                avg_std_tex = '\\\\bm{' + avg_std_tex + '}'\n",
    "\n",
    "            new_row[idx_cmp] = avg_std_tex\n",
    "\n",
    "        df_acc_latex.loc[len(df_acc_latex.index)] = new_row"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "tracked-appendix",
   "metadata": {},
   "source": [
    "### Building latex table from statistical results (pandas.dataframe)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "loving-sharing",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set hierarchical indexes for rows\n",
    "idx_iter = [datasets, [i for i in range(10, 90, 10)]]\n",
    "df_acc_latex.index = pd.MultiIndex.from_product(idx_iter, names=('Dataset', 'Sparsity (\\%)'))\n",
    "\n",
    "# Set hierarchical indexes for columns\n",
    "col_iter = [('Baseline', baseline.upper()), ('Proposed methods', 'NMF'), ('Proposed methods', 'PMF'), ('Proposed methods', 'SVD')]\n",
    "df_acc_latex.columns = pd.MultiIndex.from_tuples(col_iter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "smoking-black",
   "metadata": {},
   "outputs": [],
   "source": [
    "stats_dir = './out/KIS_21/k_2/stats'\n",
    "\n",
    "df_acc_latex.to_latex(\n",
    "    '/'.join([stats_dir, f'tex_table_{baseline}_accuracy_{u.get_datetime()}']),\n",
    "    index=True,\n",
    "    sparsify=False,\n",
    "    float_format='%.4f',\n",
    "    column_format='c',\n",
    "    multicolumn=True,\n",
    "    multicolumn_format='c',\n",
    "    multirow=True,\n",
    "    caption='Average accuracy comparison.', \n",
    "    label=f'tab_{baseline}_accuracy',\n",
    "    escape=False,\n",
    "    position='!ht')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
